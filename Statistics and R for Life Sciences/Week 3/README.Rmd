---
title: "Week 3 Notes"
author: "Enes Kemal Ergin"
date: "Tuesday, March 03, 2015"
output: html_document
---



Now that we have introduced the idea of a random variable, a null distribution, and a p-value, we are ready to describe the mathematical theory that permits us to compute p-values in practice. We will also learn about confidence intervals and power calculations. 

# Population parameters

A first step in statistical inference is to understand what population you are interested in. In the mouse weight example, we have two populations; female mice on control diet and female mice on high fat diet, and the outcome of interest was weight. We consider this population to be fixed, and the randomness comes from the sampling. One reason we have been using this dataset as an example is because we happen to have the weights of all the mice of this type. Here we download and read in this dataset:

```{r}
library(downloader)
url <- "https://raw.githubusercontent.com/genomicsclass/dagdata/master/inst/extdata/mice_pheno.csv"
filename <- tempfile()
download(url,destfile=filename)
dat <- read.csv(filename)
```

We can then access the population values and determine, for example, how many we have. For example here is the control population:

```{r}
controlPopulation <- dat[dat$Sex == "F" & dat$Diet == "chow", 3]
length(controlPopulation)
```

We usually denote these values as $x_1,\dots,x_m$. In this case $m=225$. Now we can do the same with the high fat diet population

```{r}
hfPopulation <- dat[dat$Sex == "F" & dat$Diet == "hf", 3]
length(hfPopulation)
```

and denote with $y_1,\dots,y_n, n=200$. 


We can then define summaries of interest for these population such as the mean and variance. 

the mean:

$$\mu_X = \frac{1}{m}\sum_{i=1}^m x_i \mbox{ and } \mu_Y = \frac{1}{n} \sum_{i=1}^n y_i$$

the variance:

$$\sigma_X^2 = \frac{1}{m}\sum_{i=1}^m (x_i-\mu_x)^2 \mbox{ and } \sigma_Y^2 = \frac{1}{n} \sum_{i=1}^n (y_i-\mu_y)^2$$

with the standard deviation being the square root of the variance. We refer to such quantities, that can be obtained from the population, as _population parameters_.

The question we started out asking can now be written mathematically: $\mu_Y - \mu_X = 0$ ? An
important point is that although in our special case we can easily check if this is true since we actually have
all the values, in practice we do not. So instead we take a sample and try to answer the questions with
the sample. This is the essence of statistical inference.

## Sample estimates

In the previous section, we obtained samples of 12 mice from each population. We represent these with capital letters to indicate that they are random. This is common practice in statistics, although it is not always followed. So the samples are $X_1,\dots,X_M$ and $Y_1,\dots,Y_N$ and in this case $N=M=12$. Since we want to know what $\mu_Y - \mu_X$ is we consider the sample version: $\bar{Y}-\bar{X}$  with 

$$\bar{X}=\frac{1}{M} \sum_{i=1}^M X_i \mbox{ and }\bar{Y}=\frac{1}{N} \sum_{i=1}^N Y_i$$

which is a random variable. Previously we learned about the behavior of random variables with the exercise that involved sampling over and over from the original distribution. We noted that this is not an exercise that we can execute in practice. In this particular case it would involve buying mice over and over. Here we described the mathematical theory that mathematically relates $\bar{X}$ to $\mu_X$ and $\bar{Y}$ to $\mu_Y$, which will in turn help us understand the relationship between $\bar{Y}-\bar{X}$  and $\mu_Y - \mu_X$.

---

Below we will discuss two mathematical results, the Central Limit Theorem and the t-distribution, which help us to calculate probabilities of observing events, and both are often used in science to test statistical hypotheses. They have different assumptions, but both results are similar in that through mathematical formula, we are able to calculate exact probabilities of events, if we think that certain assumptions about the data hold true.

# Central Limit Theorem 

The Central Limit Theorem (or CLT) is one of the most used mathematical results in science. It tells us that when the sample size is large the average $\bar{Y}$ of a random sample follows a normal distribution centered at the population average $\mu_Y$ and with standard deviation equal to the population standard deviation $\sigma_Y$, divided by the square root of the sample size $N$. 

Two important mathematical results you need to know are that if we subtract a constant from a random variable, the mean of the new random variable shifts by that constant. Mathematically, if $X$ is a random variable with mean $\mu$ and $a$ is a constant, the mean of $X - a$ is $\mu-a$. A similarly intuitive result holds for the standard deviation if $X$ is a random variable with mean $\mu$ and SD $\sigma$, and $a$ is a constant, then the mean and SD of $aX$ are $a \mu$ and $\|a\| \sigma$ respectively. To see how intuitive this is, imagine we subtract 10 grams from each of the mice weights, the average should also drop by that much. Similarly, we we change the units from grams to milligrams by multiplying by 1000 then the spread of the numbers becomes larger.

This implies that if we take many samples of size $N$ then the quantity 

$$
\frac{\bar{Y} - \mu}{\sigma_Y/\sqrt{N}}
$$

is approximated with a normal distribution centered at 0 and with standard deviation 1.

Now we are interested in the difference of two sample averages. Here again a mathematical result helps. If we have two random variables $X$ and $Y$ with means $\mu_X$ and $\mu_Y$ and variance $\sigma_X$ and $\sigma_Y$ respectively, then we have the following results. The mean of the sum $Y + X$ is the sum of the means $\mu_Y + \mu_X$. Using one of the facts we mentioned earlier, this implies that the mean of $Y - X = Y + aX$ with $a = -1$ which means the mean of $Y - X$ is $\mu_Y - \mu_X$. This is intuitive. However, the next result is perhaps not as intuitive.  If $X$ and $Y$ are independent of each other, as they are in our mouse example, then the variance (SD squared) of $Y + X$ is the sum of the variances $\sigma_Y^2 + \sigma_X^2$. This implies that variance of the difference $Y - X$ is the variance of $Y - aX$ with $a = -1$ which is $\sigma^2_Y + a^2 \sigma_X^2 = \sigma^2_Y + \sigma_X^2$. So the variance of the difference is also the sum of the variances. If this seems like a counter intuitive result, think that if $X$ and $Y$ are independent of each other, the sign does not really matter, it can be considered random: if $X$ is normal with certain variance, for example, so is $-X$.  Finally, another useful result is that the sum of normal variables is again normal.

All this math is very useful for the purposes of our study because we have two sample averages and are interested in the difference. Because both are normal the difference is normal as well, and the variance (the standard deviation squared) is the sum of the two variance.
Under the null hypothesis that there is no difference between the population averages, the difference between the sample averages $\hat{Y}-\hat{X}$, with $\hat{X}$ and $\hat{Y}$ the sample average for the two diets respectively, is approximated by a normal distribution centered at 0 (there is no difference) and with standard deviation $\sqrt{\sigma_X^2 +\sigma_Y^2}/\sqrt{N}$. 

This is imply that this ratio,

$$
\frac{\bar{Y}-\bar{X}}{\sqrt{\frac{\sigma_X^2}{M} + \frac{\sigma_Y^2}{N}}}
$$

is approximated by a normal distribution centered at 0 and standard deviation 1.  Using this approximation make computing p-values simple because we know the proportion of the distribution under any value. For example, only 5% values of larger than 2 (in absolute value):
```{r}
1-pnorm(2)+pnorm(-2)
```
We don't need to buy more mouse,  12 and 12 suffices.

However, we can't claim victory just yet because  we don't know the population standard deviations: $\sigma_X$ and $\sigma_Y$. These are population parameters. But we can get around this by using the sample standard deviations, call then $s_X$ and $s_Y$. These are defined as 

$$ s_X^2 = \frac{1}{N - 1} \sum_{i=1}^N (Y_i - \bar{Y})^2  \mbox{ and } s_X^2 = \frac{1}{M  -1} \sum_{i=1}^M (X_i - \bar{X})^2$$

Note that we are dividing by $N-1$ and $M-1$. There is a theoretical reason for doing this which we won't explain now. But to get an intuition think of the case when you just have 2 numbers. The average distance to the mean is basically the 1/2 the difference between the two numbers. So you really just have information from one number. This is somewhat of a minor point, the main point is that $s_X$ and $s_Y$ serve as estimates of $\sigma_X$ and $\sigma_Y$

So we can redefine our ratio as

$$
\sqrt{N} \frac{\bar{Y}-\bar{X}}{\sqrt{s_X^2 +s_Y^2}}
$$

if $M=N$ or in general,

$$
\frac{\bar{Y}-\bar{X}}{\sqrt{\frac{s_X^2}{M} + \frac{s_Y^2}{N}}}
$$

The CLT tells us that when $N$ and $M$ are large (rule of thumb is 30) this random variable is normally distributed with mean 0 and SD 1. Thus we can compute p-values using the function `pnorm`.

## The t-distribution

When the CLT does not apply, there another option that does not rely on large samples (what we call asymptotic results). When a the original population from which a random variable, say $Y$, is sampled is normally distributed with mean 0 then we can calculate the distribution of 

$$
\sqrt{N} \frac{\bar{Y}}{s_Y}
$$

Note that this is the ratio of two random variables so it is not necessarily normal. The fact that the denominator can be small by chance increases the probability of observing large values. [William Sealy Gosset](http://en.wikipedia.org/wiki/William_Sealy_Gosset), an employ of Guinness, deciphered the distribution of this random variable and published a paper under the pseudonym "student". This the distribution is called the Student's t-distribution. Later we will learn more about how this result is used.

Here we will use the mice phenotypes data as example:

```{r}
library(downloader)
url <- "https://raw.githubusercontent.com/genomicsclass/dagdata/master/inst/extdata/mice_pheno.csv"
filename <- "mice_pheno.csv"
if (!file.exists(filename)) download(url, destfile=filename)
dat <- read.csv(filename)
controlPopulation <- dat[dat$Sex=="F" & dat$Diet=="chow",3]
hfPopulation <- dat[dat$Sex=="F" & dat$Diet=="hf",3]
```

It is important to keep in mind that what we are assuming to be normal here is the distribution of $y_1,y_2,\dots,y_n$ not the random variable $\bar{Y}$. Although we do not get to do this in practice, in this illustrative example we get to see this distribution for both controls and high fat diet mice:

```{r, fig.height=3.5}
library(rafalib)
mypar2(1,2)
hist(hfPopulation)
hist(controlPopulation)
```

We can use qq-plots to confirm that the distribution are relatively close to being normally distributed.

```{r,fig.height=3.5}
mypar2(1,2)
qqnorm(hfPopulation);qqline(hfPopulation)
qqnorm(controlPopulation);qqline(controlPopulation)
```

The larger the sample, the more forgiving the result is to the weakness of this approximation. We will later see that for this particular dataset the t-distribution works well even for  sample sizes as small as 3.

---

# Central Limit Theorem Practices

```{r,results=FALSE,echo=FALSE}
set.seed(1) ##so that we get same results
```

Let's use our data to see how well the central limit approximates sample averages from our data. We will leverage our entire population dataset to compare the results we obtain by actually sampling from the distribtuion to what the CLT predicts.  

```{r}
library(downloader)
url <- "https://raw.githubusercontent.com/genomicsclass/dagdata/master/inst/extdata/mice_pheno.csv"
filename <- tempfile()
download(url,destfile=filename)
dat <- read.csv(filename)
head(dat)
```

Start by selecting only female mice since males and females have different weights.

```{r}
hfPopulation <- dat[dat$Sex=="F" & dat$Diet=="hf",3]
controlPopulation <- dat[dat$Sex=="F" & dat$Diet=="chow",3]
```

We can compute the population parameters of interest using the mean function.

```{r}
mu_hf <- mean(hfPopulation)
mu_control <- mean(controlPopulation)
print(mu_hf - mu_control)
```

Compute the population standard deviations as well. Note that we do not use the R function `sd` because this is to compute the population based estimates that divide by the sample size - 1. 

We can see that with R code
```{r}
x<-controlPopulation
N<-length(x)
popvar <- mean((x-mean(x))^2)
identical(var(x),popvar)
identical(var(x)*(N-1)/N, popvar)
```

So to be mathematically correct we do not use `sd` or  `var`. I am going to define a function for this:
```{r}
popvar <- function(x) mean( (x-mean(x))^2)
popsd <- function(x) sqrt(popvar(x)) 
```

Now we can compute the popultion SD:

```{r}
sd_hf <- popsd(hfPopulation)
sd_control <- popsd(controlPopulation)
```

Remember, that in practice we do not get to compute these population parameters,
These are values we do not get to see. In general, we want to estimate them from samples. 
```{r}
N <- 12
hf <- sample(hfPopulation,12)
control <- sample(controlPopulation,12)
```
The CLT tells us that, for large $N$, each of these is approximately normal with average population mean and standard error population variance divided by $N$. We mentioned that a rule of thumb is that $N$ should be 30 or more. But that is just a rule of thumb as the precisness of the approximation depends on the population distribution. Here we can acually check the approximation and we do that for various values of $N$.

Now we use sapply and replicate instead of for loops, which is recommended.
```{r}
Ns <- c(3,12,25,50)
B <- 10000 #number of simulations
res <-  sapply(Ns,function(n){
  replicate(B,mean(sample(hfPopulation,n))-mean(sample(controlPopulation,n)))
})
```

Now we can use qq-plots to see how well CLT approximations  works for these. If in fact the normal distribution is a good approximation the points should fall on a straight line when compared to normal quantiles. The more it deviates, the worse the approximation.  We also show, in the title, the average and SD of the observed distribution showing how the SD decreases with $\sqrt{N}$ as predicted. 
```{r}
library(rafalib)
mypar2(2,2)
for(i in seq(along=Ns)){
  title <- paste("N=",Ns[i],"Avg=",signif(mean(res[,i]),3),"SD=",signif(popsd(res[,i]),3)) ##popsd defined above
  qqnorm(res[,i],main=title)
  qqline(res[,i],col=2)
}
```

Here we see a pretty good fit even for 3. Why is this? Because the population itself is relatively close to normally distributed, the averages are close to normal as well, (the sum of normals is normals). Now in practice we actually calculate a ratio, we divide by the estimate standard deviation. Here is where the sample size starts to matter more.

```{r}
Ns <- c(3,12,25,50)
B <- 10000 #number of simulations
##function to compute a t-stat
computetstat <- function(n){
  y<-sample(hfPopulation,n)
  x<-sample(controlPopulation,n)
  (mean(y)-mean(x))/sqrt(var(y)/n+var(x)/n)
}
res <-  sapply(Ns,function(n){
  replicate(B,computetstat(n))
})
mypar2(2,2)
for(i in seq(along=Ns)){
  qqnorm(res[,i],main=Ns[i])
  qqline(res[,i],col=2)
}
```

Now we see that for $N=3$ the CLT does not provide a usable approximation. For $N=12$ their is a slight deviation at the higher values, although the approximation appears useful. For 25 and 50 the appoximation is spot on. 

Note that this simulation is not meant as proof that $N=12$ is large enough, in general. It only applies to this dataset and, as mentioned above, we will not be able to perform this simulation in most situation. We only use the simulation to illustrate the conecepts behind the CLT. In future sections we will describe approaches we actually use in practice.

---

# Introduction

Now we will demonstrate how to obtain a p-value in practice. We will load experimental data and walk you through the steps used to form a t-statistics and compute a p-value. Note that we can perform this task with just a few lines of code (go to end of section to see them). However, to understand the concepts we will construct a t-statistic for "scratch".

```{r,results=FALSE,echo=FALSE}
set.seed(1) ##so that we get same results
```

## Read in and prepare data
We start by reading in the data. A first important step is to identify which rows are associated with treatment and control:
```{r}
library(downloader)
url <- "https://raw.githubusercontent.com/genomicsclass/dagdata/master/inst/extdata/femaleMiceWeights.csv"
filename <- "femaleMiceWeights.csv"
if (!file.exists(filename)) download(url,filename)
dat <- read.csv(filename)
head(dat) ##quick look at the data 
controlIndex <- which(dat$Diet=="chow")
treatmentIndex <- which(dat$Diet=="hf")
```
and then obtain the data and observed difference in mean:
```{r}
control <- dat[controlIndex,2]
treatment <- dat[treatmentIndex,2]
diff <- mean(treatment)-mean(control)
print(diff)
```

We are asked to report a p-value. What do we do? We learned that `diff`, refered to as the _observed effect size_ is a random variable. Under the null hypothesis what is the distribution of this random variable? Let's use what we learned.

Under the null, the mean of the distribution of `diff` is 0. What about the standard deviation? 

To simplify, let's start with `mean(control)`. This is also a random variable. We want to know the standard error of the distribution of this random variable, which from now on we will call a standard error (SE). In statistics we call the standard deviation of the distribution of a random variable, the standard error of the random variable. Previously, we learned that statistical theory tells us that the standard error of this random variable is the population standard deviation divided by the square root of the square root of the sample size. The formula we showed was

$$ SE(\bar{X}) = \sigma / \sqrt{N}$$

A problem is that we do not know the population standard deviation. So we use the sample standard deviation as an estimate. In R we simply use the `sd` function and the SE is simply

```{r}
sd(control)/sqrt(length(control))
```

This is the SE of the sample average but we actually want the SE of `diff`. We saw how statistical theory tells us that the variance of the difference of two random variables is the sum of it's variances, so we compute the variance and take the square root:

```{r}
se <- sqrt( var(treatment)/length(treatment) + var(control)/length(control) )
```

Statistical theory tells us that if we divide a random variable by it's SE, we get a new random variable with SE=1.

```{r}
tstat <- diff/se 
```

This ratio is what we call the t-statistics. It's the ratio of two random variables, thus a random variable. Once we know the distribution of this random variable then we can easily compute a p-value.

The central limit theorem (CLT) tells us that for large sample sizes both sample averages `mean(treatment)` and `mean(control)` are normal. Statistical theory tells us that the difference of two normal is again normal,  so CLT tells us that `tstat` is  approximately normal with mean 0 (the null hypothesis) and SD 1 (we divided by it's SE). 

So now to calculate a p-value all we do is ask, how often is a normally distributed random variable exceed `diff`. R has a function specifically built to answer this question: `pnorm`. `pnorm(a)` returns the probability that random variable following the standard normal distribution falls below `a`. To obtain the probability that it is larger than `a` we simply use `1-pnorm(a)`. We want to know the probability of seeing something as extreme as `diff`: either smaller (more negative) than `-abs(diff)` or larger than `abs(diff)`:

```{r}
righttail <- 1-pnorm(abs(tstat)) 
lefttail <- pnorm(-abs(tstat))
pval <- lefttail + righttail
print(pval)
```

In this case the p-value is 0.04 and we would call it significant.

No there is a problem here. CLT works for large samples, but is 12 large enough? A rule of thumb for CLT is that 30 is a large enough sample size (but this is just a rule of thumb).  However, there is another option than using CLT.

<a name="smallsample"></a>

## The t-distribution in practice

As described earlier, it turns out that statistical theory offers another useful result. If the distribution of the population is normal then we can work out the exact distribution of the t-statistic without the need for the CLT. Now note that this is a big "if" given with small samples it i hard to check if the population is normal. But for something like weight we suspect that the population distribution is likely well approximated by normal and use this result. Furthermore, we can look at qq-plot for the sample and this show that the approximation is at least close:

```{r, fig.height=3.5}
library(rafalib)
mypar2(1,2)
qqnorm(treatment);qqline(treatment,col=2)
qqnorm(control);qqline(control,col=2)
```

If we use this approximation, then statistical theory tells us that distribution of the random variable `tstat` follows a t-distribution. This is a much more complicated distribution than the normal that depends on another parameter called degrees of freedom. R has a nice function that actually computes everything for us.

```{r}
t.test(treatment,control)
```

Note that the p-value is slightly bigger now. This is to be expected because the CLT approximation considers the denominator of t-stat practically fixed while the t-distribution approximation takes into account that it is random variable and that the smaller the sample size the more it varies.

It may be confusing that one approximation gave us one p-value and another gave us another because we expect there to be just one answer. Later, in the power calculation section, we will describe type I and type II errors. As a preview we point out that the test based on the CLT approximation is more likely to incorrectly reject the null (false positive) while the t-distribution is more likely to incorrectly accept the null (false negative).

## Running the t-test in practice

Now that we have gone over the concepts, we can show the code that one actually would run to compute a t-test

```{r}
dat <- read.csv(filename)
controlIndex <- which(dat$Diet=="chow")
treatmentIndex <- which(dat$Diet=="hf")
control <- dat[controlIndex,2]
treatment <- dat[treatmentIndex,2]
t.test(treatment,control)
```

